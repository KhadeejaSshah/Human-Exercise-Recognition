{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khadeeja Shah\n",
    "21i 1653\n",
    "Deep LEARNING\n",
    "Assignment 2\n",
    "Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human Exercise Recognition: Integrating YOLO for Object Detection, 3D Pose\n",
    "Estimation, and CNN-Based Exercise Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras import models, layers\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO  #we r using YOLOv5\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "a = pd.read_csv('q1/landmarks.csv')  \n",
    "b = pd.read_csv('q1/3d_distances.csv')  \n",
    "c = pd.read_csv('q1/angles.csv')  \n",
    "d = pd.read_csv('q1/xyz_distances.csv')  \n",
    "\n",
    "#prediction\n",
    "e = pd.read_csv('q1/labels.csv') \n",
    "\n",
    "yy = label_encoder.fit_transform(e['pose'].values)\n",
    "wholedf = pd.concat([a, b, c, d], axis=1)\n",
    "X = wholedf.values  \n",
    "y = to_categorical(yy)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "a = pd.read_csv('q1/landmarks.csv')  \n",
    "# d = pd.read_csv('q1/3d_distances.csv')  \n",
    "# c = pd.read_csv('q1/angles.csv')  \n",
    "# b = pd.read_csv('q1/xyz_distances.csv')  \n",
    "\n",
    "#prediction\n",
    "e = pd.read_csv('q1/labels.csv') \n",
    "\n",
    "yy = label_encoder.fit_transform(e['pose'].values)\n",
    "#wholedf = pd.concat([a], axis=1)\n",
    "X = a.values  \n",
    "y = to_categorical(yy)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pose_id', 'x_nose', 'y_nose', 'z_nose', 'x_left_eye_inner',\n",
       "       'y_left_eye_inner', 'z_left_eye_inner', 'x_left_eye', 'y_left_eye',\n",
       "       'z_left_eye', 'x_left_eye_outer', 'y_left_eye_outer',\n",
       "       'z_left_eye_outer', 'x_right_eye_inner', 'y_right_eye_inner',\n",
       "       'z_right_eye_inner', 'x_right_eye', 'y_right_eye', 'z_right_eye',\n",
       "       'x_right_eye_outer', 'y_right_eye_outer', 'z_right_eye_outer',\n",
       "       'x_left_ear', 'y_left_ear', 'z_left_ear', 'x_right_ear', 'y_right_ear',\n",
       "       'z_right_ear', 'x_mouth_left', 'y_mouth_left', 'z_mouth_left',\n",
       "       'x_mouth_right', 'y_mouth_right', 'z_mouth_right', 'x_left_shoulder',\n",
       "       'y_left_shoulder', 'z_left_shoulder', 'x_right_shoulder',\n",
       "       'y_right_shoulder', 'z_right_shoulder', 'x_left_elbow', 'y_left_elbow',\n",
       "       'z_left_elbow', 'x_right_elbow', 'y_right_elbow', 'z_right_elbow',\n",
       "       'x_left_wrist', 'y_left_wrist', 'z_left_wrist', 'x_right_wrist',\n",
       "       'y_right_wrist', 'z_right_wrist', 'x_left_pinky_1', 'y_left_pinky_1',\n",
       "       'z_left_pinky_1', 'x_right_pinky_1', 'y_right_pinky_1',\n",
       "       'z_right_pinky_1', 'x_left_index_1', 'y_left_index_1', 'z_left_index_1',\n",
       "       'x_right_index_1', 'y_right_index_1', 'z_right_index_1',\n",
       "       'x_left_thumb_2', 'y_left_thumb_2', 'z_left_thumb_2', 'x_right_thumb_2',\n",
       "       'y_right_thumb_2', 'z_right_thumb_2', 'x_left_hip', 'y_left_hip',\n",
       "       'z_left_hip', 'x_right_hip', 'y_right_hip', 'z_right_hip',\n",
       "       'x_left_knee', 'y_left_knee', 'z_left_knee', 'x_right_knee',\n",
       "       'y_right_knee', 'z_right_knee', 'x_left_ankle', 'y_left_ankle',\n",
       "       'z_left_ankle', 'x_right_ankle', 'y_right_ankle', 'z_right_ankle',\n",
       "       'x_left_heel', 'y_left_heel', 'z_left_heel', 'x_right_heel',\n",
       "       'y_right_heel', 'z_right_heel', 'x_left_foot_index',\n",
       "       'y_left_foot_index', 'z_left_foot_index', 'x_right_foot_index',\n",
       "       'y_right_foot_index', 'z_right_foot_index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.drop(columns=['z_left_pinky_1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = a.values  \n",
    "y = to_categorical(yy)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[          0,     -5.8895,     -57.638, ...,    0.092779,      45.842,      41.428],\n",
       "       [          1,     -4.2555,     -62.936, ...,     -5.0906,      65.642,     -42.878],\n",
       "       [          2,     -2.8789,      -61.71, ...,     -4.4526,      62.494,     -53.805],\n",
       "       ...,\n",
       "       [       1369,     -5.2467,     -51.167, ...,      4.8939,      69.189,      -12.64],\n",
       "       [       1370,     -9.4546,     -50.395, ...,      3.2362,      65.236,     -16.616],\n",
       "       [       1371,     -7.6425,     -51.769, ...,      5.5172,      69.684,     -21.595]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pose_id</th>\n",
       "      <th>x_nose</th>\n",
       "      <th>y_nose</th>\n",
       "      <th>z_nose</th>\n",
       "      <th>x_left_eye_inner</th>\n",
       "      <th>y_left_eye_inner</th>\n",
       "      <th>z_left_eye_inner</th>\n",
       "      <th>x_left_eye</th>\n",
       "      <th>y_left_eye</th>\n",
       "      <th>z_left_eye</th>\n",
       "      <th>...</th>\n",
       "      <th>z_left_heel</th>\n",
       "      <th>x_right_heel</th>\n",
       "      <th>y_right_heel</th>\n",
       "      <th>z_right_heel</th>\n",
       "      <th>x_left_foot_index</th>\n",
       "      <th>y_left_foot_index</th>\n",
       "      <th>z_left_foot_index</th>\n",
       "      <th>x_right_foot_index</th>\n",
       "      <th>y_right_foot_index</th>\n",
       "      <th>z_right_foot_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-5.889507</td>\n",
       "      <td>-57.637520</td>\n",
       "      <td>-45.019750</td>\n",
       "      <td>-4.656085</td>\n",
       "      <td>-62.832863</td>\n",
       "      <td>-44.571823</td>\n",
       "      <td>-3.302626</td>\n",
       "      <td>-63.386856</td>\n",
       "      <td>-44.567863</td>\n",
       "      <td>...</td>\n",
       "      <td>56.852562</td>\n",
       "      <td>-0.842025</td>\n",
       "      <td>35.037060</td>\n",
       "      <td>50.565020</td>\n",
       "      <td>5.842190</td>\n",
       "      <td>45.971020</td>\n",
       "      <td>50.263714</td>\n",
       "      <td>0.092779</td>\n",
       "      <td>45.842150</td>\n",
       "      <td>41.427795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-4.255504</td>\n",
       "      <td>-62.935925</td>\n",
       "      <td>-128.907500</td>\n",
       "      <td>-2.977403</td>\n",
       "      <td>-67.035990</td>\n",
       "      <td>-124.258545</td>\n",
       "      <td>-2.215265</td>\n",
       "      <td>-67.198250</td>\n",
       "      <td>-124.263240</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.129170</td>\n",
       "      <td>-1.298891</td>\n",
       "      <td>54.733307</td>\n",
       "      <td>-6.886051</td>\n",
       "      <td>3.980098</td>\n",
       "      <td>65.370830</td>\n",
       "      <td>-49.023930</td>\n",
       "      <td>-5.090634</td>\n",
       "      <td>65.641780</td>\n",
       "      <td>-42.878056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-2.878917</td>\n",
       "      <td>-61.709988</td>\n",
       "      <td>-137.453340</td>\n",
       "      <td>-1.619050</td>\n",
       "      <td>-65.693750</td>\n",
       "      <td>-132.181660</td>\n",
       "      <td>-0.785822</td>\n",
       "      <td>-65.814340</td>\n",
       "      <td>-132.184070</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.904400</td>\n",
       "      <td>-2.119770</td>\n",
       "      <td>51.265694</td>\n",
       "      <td>-15.554097</td>\n",
       "      <td>1.994894</td>\n",
       "      <td>62.725025</td>\n",
       "      <td>-57.717957</td>\n",
       "      <td>-4.452602</td>\n",
       "      <td>62.494457</td>\n",
       "      <td>-53.804527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-4.242575</td>\n",
       "      <td>-60.371220</td>\n",
       "      <td>-135.094830</td>\n",
       "      <td>-3.118133</td>\n",
       "      <td>-64.416000</td>\n",
       "      <td>-129.995930</td>\n",
       "      <td>-2.369744</td>\n",
       "      <td>-64.603290</td>\n",
       "      <td>-130.003400</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.855729</td>\n",
       "      <td>-1.485475</td>\n",
       "      <td>59.729427</td>\n",
       "      <td>1.433403</td>\n",
       "      <td>1.950102</td>\n",
       "      <td>68.187256</td>\n",
       "      <td>-42.989098</td>\n",
       "      <td>-4.573338</td>\n",
       "      <td>68.144350</td>\n",
       "      <td>-34.117043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.805543</td>\n",
       "      <td>-56.178570</td>\n",
       "      <td>-41.124413</td>\n",
       "      <td>-0.055174</td>\n",
       "      <td>-58.501305</td>\n",
       "      <td>-37.938560</td>\n",
       "      <td>0.456936</td>\n",
       "      <td>-58.473960</td>\n",
       "      <td>-37.954430</td>\n",
       "      <td>...</td>\n",
       "      <td>47.124107</td>\n",
       "      <td>-2.455719</td>\n",
       "      <td>52.861732</td>\n",
       "      <td>45.936783</td>\n",
       "      <td>2.699764</td>\n",
       "      <td>57.254112</td>\n",
       "      <td>27.531416</td>\n",
       "      <td>-2.288348</td>\n",
       "      <td>57.803005</td>\n",
       "      <td>26.288315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>1367</td>\n",
       "      <td>-2.802355</td>\n",
       "      <td>-52.953636</td>\n",
       "      <td>33.939075</td>\n",
       "      <td>-2.539375</td>\n",
       "      <td>-54.988766</td>\n",
       "      <td>28.330921</td>\n",
       "      <td>-2.769386</td>\n",
       "      <td>-54.978294</td>\n",
       "      <td>28.330809</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.383635</td>\n",
       "      <td>9.620919</td>\n",
       "      <td>62.689760</td>\n",
       "      <td>1.940604</td>\n",
       "      <td>-9.083422</td>\n",
       "      <td>66.475450</td>\n",
       "      <td>-21.541600</td>\n",
       "      <td>7.629234</td>\n",
       "      <td>64.127884</td>\n",
       "      <td>-0.578571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>1368</td>\n",
       "      <td>-3.224722</td>\n",
       "      <td>-53.435062</td>\n",
       "      <td>24.807423</td>\n",
       "      <td>-3.021559</td>\n",
       "      <td>-55.519997</td>\n",
       "      <td>19.032497</td>\n",
       "      <td>-3.251536</td>\n",
       "      <td>-55.513744</td>\n",
       "      <td>19.029673</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.191764</td>\n",
       "      <td>8.673649</td>\n",
       "      <td>61.696476</td>\n",
       "      <td>17.039696</td>\n",
       "      <td>-9.507468</td>\n",
       "      <td>62.937355</td>\n",
       "      <td>-15.579117</td>\n",
       "      <td>6.635663</td>\n",
       "      <td>58.774628</td>\n",
       "      <td>16.410402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>1369</td>\n",
       "      <td>-5.246736</td>\n",
       "      <td>-51.167410</td>\n",
       "      <td>42.242527</td>\n",
       "      <td>-4.634136</td>\n",
       "      <td>-53.948723</td>\n",
       "      <td>36.914402</td>\n",
       "      <td>-4.680208</td>\n",
       "      <td>-53.979324</td>\n",
       "      <td>36.914505</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.383213</td>\n",
       "      <td>7.567497</td>\n",
       "      <td>68.391500</td>\n",
       "      <td>-8.151683</td>\n",
       "      <td>-12.653155</td>\n",
       "      <td>70.019870</td>\n",
       "      <td>-22.984924</td>\n",
       "      <td>4.893911</td>\n",
       "      <td>69.188810</td>\n",
       "      <td>-12.639636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>1370</td>\n",
       "      <td>-9.454565</td>\n",
       "      <td>-50.395477</td>\n",
       "      <td>48.190674</td>\n",
       "      <td>-9.892803</td>\n",
       "      <td>-52.576120</td>\n",
       "      <td>42.548897</td>\n",
       "      <td>-10.057731</td>\n",
       "      <td>-52.432430</td>\n",
       "      <td>42.547436</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.611992</td>\n",
       "      <td>3.883872</td>\n",
       "      <td>67.364784</td>\n",
       "      <td>-4.632682</td>\n",
       "      <td>-12.399118</td>\n",
       "      <td>66.006620</td>\n",
       "      <td>-19.250687</td>\n",
       "      <td>3.236249</td>\n",
       "      <td>65.236305</td>\n",
       "      <td>-16.615772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>1371</td>\n",
       "      <td>-7.642476</td>\n",
       "      <td>-51.768620</td>\n",
       "      <td>45.853340</td>\n",
       "      <td>-8.386562</td>\n",
       "      <td>-53.711056</td>\n",
       "      <td>40.694260</td>\n",
       "      <td>-8.754703</td>\n",
       "      <td>-53.525986</td>\n",
       "      <td>40.691055</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.586429</td>\n",
       "      <td>7.314923</td>\n",
       "      <td>68.713990</td>\n",
       "      <td>-10.399548</td>\n",
       "      <td>-9.271418</td>\n",
       "      <td>69.022390</td>\n",
       "      <td>-19.419860</td>\n",
       "      <td>5.517189</td>\n",
       "      <td>69.684000</td>\n",
       "      <td>-21.594507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pose_id    x_nose     y_nose      z_nose  x_left_eye_inner  \\\n",
       "0           0 -5.889507 -57.637520  -45.019750         -4.656085   \n",
       "1           1 -4.255504 -62.935925 -128.907500         -2.977403   \n",
       "2           2 -2.878917 -61.709988 -137.453340         -1.619050   \n",
       "3           3 -4.242575 -60.371220 -135.094830         -3.118133   \n",
       "4           4 -0.805543 -56.178570  -41.124413         -0.055174   \n",
       "...       ...       ...        ...         ...               ...   \n",
       "1367     1367 -2.802355 -52.953636   33.939075         -2.539375   \n",
       "1368     1368 -3.224722 -53.435062   24.807423         -3.021559   \n",
       "1369     1369 -5.246736 -51.167410   42.242527         -4.634136   \n",
       "1370     1370 -9.454565 -50.395477   48.190674         -9.892803   \n",
       "1371     1371 -7.642476 -51.768620   45.853340         -8.386562   \n",
       "\n",
       "      y_left_eye_inner  z_left_eye_inner  x_left_eye  y_left_eye  z_left_eye  \\\n",
       "0           -62.832863        -44.571823   -3.302626  -63.386856  -44.567863   \n",
       "1           -67.035990       -124.258545   -2.215265  -67.198250 -124.263240   \n",
       "2           -65.693750       -132.181660   -0.785822  -65.814340 -132.184070   \n",
       "3           -64.416000       -129.995930   -2.369744  -64.603290 -130.003400   \n",
       "4           -58.501305        -37.938560    0.456936  -58.473960  -37.954430   \n",
       "...                ...               ...         ...         ...         ...   \n",
       "1367        -54.988766         28.330921   -2.769386  -54.978294   28.330809   \n",
       "1368        -55.519997         19.032497   -3.251536  -55.513744   19.029673   \n",
       "1369        -53.948723         36.914402   -4.680208  -53.979324   36.914505   \n",
       "1370        -52.576120         42.548897  -10.057731  -52.432430   42.547436   \n",
       "1371        -53.711056         40.694260   -8.754703  -53.525986   40.691055   \n",
       "\n",
       "      ...  z_left_heel  x_right_heel  y_right_heel  z_right_heel  \\\n",
       "0     ...    56.852562     -0.842025     35.037060     50.565020   \n",
       "1     ...   -14.129170     -1.298891     54.733307     -6.886051   \n",
       "2     ...   -19.904400     -2.119770     51.265694    -15.554097   \n",
       "3     ...    -6.855729     -1.485475     59.729427      1.433403   \n",
       "4     ...    47.124107     -2.455719     52.861732     45.936783   \n",
       "...   ...          ...           ...           ...           ...   \n",
       "1367  ...   -20.383635      9.620919     62.689760      1.940604   \n",
       "1368  ...   -15.191764      8.673649     61.696476     17.039696   \n",
       "1369  ...   -21.383213      7.567497     68.391500     -8.151683   \n",
       "1370  ...    -8.611992      3.883872     67.364784     -4.632682   \n",
       "1371  ...   -10.586429      7.314923     68.713990    -10.399548   \n",
       "\n",
       "      x_left_foot_index  y_left_foot_index  z_left_foot_index  \\\n",
       "0              5.842190          45.971020          50.263714   \n",
       "1              3.980098          65.370830         -49.023930   \n",
       "2              1.994894          62.725025         -57.717957   \n",
       "3              1.950102          68.187256         -42.989098   \n",
       "4              2.699764          57.254112          27.531416   \n",
       "...                 ...                ...                ...   \n",
       "1367          -9.083422          66.475450         -21.541600   \n",
       "1368          -9.507468          62.937355         -15.579117   \n",
       "1369         -12.653155          70.019870         -22.984924   \n",
       "1370         -12.399118          66.006620         -19.250687   \n",
       "1371          -9.271418          69.022390         -19.419860   \n",
       "\n",
       "      x_right_foot_index  y_right_foot_index  z_right_foot_index  \n",
       "0               0.092779           45.842150           41.427795  \n",
       "1              -5.090634           65.641780          -42.878056  \n",
       "2              -4.452602           62.494457          -53.804527  \n",
       "3              -4.573338           68.144350          -34.117043  \n",
       "4              -2.288348           57.803005           26.288315  \n",
       "...                  ...                 ...                 ...  \n",
       "1367            7.629234           64.127884           -0.578571  \n",
       "1368            6.635663           58.774628           16.410402  \n",
       "1369            4.893911           69.188810          -12.639636  \n",
       "1370            3.236249           65.236305          -16.615772  \n",
       "1371            5.517189           69.684000          -21.594507  \n",
       "\n",
       "[1372 rows x 99 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[          1,           0,           0, ...,           0,           0,           0],\n",
       "       [          1,           0,           0, ...,           0,           0,           0],\n",
       "       [          1,           0,           0, ...,           0,           0,           0],\n",
       "       ...,\n",
       "       [          0,           0,           0, ...,           0,           0,           1],\n",
       "       [          0,           0,           0, ...,           0,           0,           1],\n",
       "       [          0,           0,           0, ...,           0,           0,           1]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i_req = 174  \n",
    "# if X.shape[1] != i_req:\n",
    "#     print(\"we want 174 features exact\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "35/35 [==============================] - 4s 44ms/step - loss: 3.0571 - accuracy: 0.4120 - val_loss: 10.2178 - val_accuracy: 0.0291\n",
      "Epoch 2/30\n",
      "35/35 [==============================] - 1s 35ms/step - loss: 0.9141 - accuracy: 0.6490 - val_loss: 13.9168 - val_accuracy: 0.0327\n",
      "Epoch 3/30\n",
      "35/35 [==============================] - 1s 35ms/step - loss: 0.5528 - accuracy: 0.7830 - val_loss: 15.4119 - val_accuracy: 0.0291\n",
      "Epoch 4/30\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 0.4272 - accuracy: 0.8633 - val_loss: 19.2957 - val_accuracy: 0.0327\n",
      "Epoch 5/30\n",
      "35/35 [==============================] - 1s 25ms/step - loss: 0.3175 - accuracy: 0.8988 - val_loss: 15.3924 - val_accuracy: 0.0327\n",
      "Epoch 6/30\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 0.3416 - accuracy: 0.8897 - val_loss: 21.3322 - val_accuracy: 0.0327\n",
      "Epoch 7/30\n",
      "35/35 [==============================] - 1s 27ms/step - loss: 0.2365 - accuracy: 0.9262 - val_loss: 22.7108 - val_accuracy: 0.0327\n",
      "Epoch 8/30\n",
      "35/35 [==============================] - 1s 27ms/step - loss: 0.2428 - accuracy: 0.9152 - val_loss: 22.8381 - val_accuracy: 0.0327\n",
      "Epoch 9/30\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 0.1994 - accuracy: 0.9335 - val_loss: 20.5039 - val_accuracy: 0.0291\n",
      "Epoch 10/30\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 0.1937 - accuracy: 0.9335 - val_loss: 23.5402 - val_accuracy: 0.0327\n",
      "Epoch 11/30\n",
      "35/35 [==============================] - 1s 28ms/step - loss: 0.1746 - accuracy: 0.9444 - val_loss: 18.6436 - val_accuracy: 0.0291\n",
      "Epoch 12/30\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 0.1383 - accuracy: 0.9499 - val_loss: 20.1802 - val_accuracy: 0.0327\n",
      "Epoch 13/30\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 0.1434 - accuracy: 0.9535 - val_loss: 23.3465 - val_accuracy: 0.0327\n",
      "Epoch 14/30\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 0.1099 - accuracy: 0.9572 - val_loss: 19.0744 - val_accuracy: 0.0327\n",
      "Epoch 15/30\n",
      "35/35 [==============================] - 1s 27ms/step - loss: 0.1372 - accuracy: 0.9462 - val_loss: 21.7192 - val_accuracy: 0.0327\n",
      "Epoch 16/30\n",
      "35/35 [==============================] - 1s 27ms/step - loss: 0.1087 - accuracy: 0.9572 - val_loss: 26.3754 - val_accuracy: 0.0327\n",
      "Epoch 17/30\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 0.0943 - accuracy: 0.9672 - val_loss: 25.1508 - val_accuracy: 0.0327\n",
      "Epoch 18/30\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 0.1096 - accuracy: 0.9553 - val_loss: 23.8446 - val_accuracy: 0.0327\n",
      "Epoch 19/30\n",
      "35/35 [==============================] - 1s 28ms/step - loss: 0.1363 - accuracy: 0.9590 - val_loss: 19.5167 - val_accuracy: 0.0327\n",
      "Epoch 20/30\n",
      "35/35 [==============================] - 1s 25ms/step - loss: 0.1235 - accuracy: 0.9599 - val_loss: 30.6977 - val_accuracy: 0.0327\n",
      "Epoch 21/30\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 0.0934 - accuracy: 0.9681 - val_loss: 26.4000 - val_accuracy: 0.0327\n",
      "Epoch 22/30\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 0.0832 - accuracy: 0.9717 - val_loss: 29.4137 - val_accuracy: 0.0327\n",
      "Epoch 23/30\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 0.1039 - accuracy: 0.9644 - val_loss: 35.7341 - val_accuracy: 0.0327\n",
      "Epoch 24/30\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 0.0776 - accuracy: 0.9772 - val_loss: 26.2239 - val_accuracy: 0.0327\n",
      "Epoch 25/30\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 0.0611 - accuracy: 0.9790 - val_loss: 30.7242 - val_accuracy: 0.0327\n",
      "Epoch 26/30\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 0.0793 - accuracy: 0.9690 - val_loss: 23.9180 - val_accuracy: 0.0327\n",
      "Epoch 27/30\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 0.0451 - accuracy: 0.9827 - val_loss: 31.4117 - val_accuracy: 0.0327\n",
      "Epoch 28/30\n",
      "35/35 [==============================] - 1s 27ms/step - loss: 0.1554 - accuracy: 0.9572 - val_loss: 23.9196 - val_accuracy: 0.0327\n",
      "Epoch 29/30\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 0.0572 - accuracy: 0.9772 - val_loss: 28.2191 - val_accuracy: 0.0327\n",
      "Epoch 30/30\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 0.0687 - accuracy: 0.9790 - val_loss: 24.3597 - val_accuracy: 0.0327\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 4.8912 - accuracy: 0.8032\n",
      "Training Accuracy of 1D CNN: 80.32%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  \n",
    "model = models.Sequential() # because adding layers.\n",
    "\n",
    "#will add 3 layer\n",
    "model.add(layers.Conv1D(64, kernel_size=3, activation='relu', padding='same', input_shape=(X.shape[1], 1)))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Conv1D(128, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Conv1D(256, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "# stride is 1 by default.\n",
    "# 64 128 256\n",
    "\n",
    "# flatten it\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "#connect each neuron to every other for better answers. \n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))  \n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "#final\n",
    "model.add(layers.Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X, y, epochs=30, batch_size=32, validation_split=0.2)\n",
    "train_loss, train_accuracy = model.evaluate(X, y)\n",
    "print(f'Training Accuracy of 1D CNN: {train_accuracy * 100:.2f}%')\n",
    "\n",
    "# Save the trained model\n",
    "model.save('1dcnnhello.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('1dcnnhello.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yolo v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bounding Box Detection Using YOLO\n",
    "# using yolo v5 as it doesnt require additional weights and cfg files like v3.\n",
    "\n",
    "def BoundingBoxDetection(image):\n",
    "    v5 = YOLO('yolov5s.pt')  \n",
    "    results = v5(image)\n",
    "\n",
    "    # model gives boxes and labels as answer along with details.\n",
    "    data = results[0].boxes  \n",
    "    # we only want class  which is person.\n",
    "    for i in data:\n",
    "        l = int(i.cls)  \n",
    "        if l == 0:\n",
    "            box = i.xyxy[0] # got the box.\n",
    "            x_min, y_min, x_max, y_max = map(int, box)  # original format.\n",
    "            \n",
    "            cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)  # Dark blue color\n",
    "            ci = image[y_min:y_max, x_min:x_max] # cropping the image.\n",
    "            return ci, image  \n",
    "    #if we dont get a person then just return image.    \n",
    "    return None, image \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "i_req = 99  # Now expecting 99 features (33 landmarks * 3 coordinates)\n",
    "\n",
    "if X.shape[1] != i_req:\n",
    "    print(\"we want exact 99 featurs only as media pipe take 99.\")\n",
    "\n",
    "def Pose3DEstimation(image):\n",
    "    pp = mp.solutions.pose  # Real-time pose estimation.\n",
    "    pose = pp.Pose(static_image_mode=True, model_complexity=2, enable_segmentation=False)  # We only need 1 image.\n",
    "    ii = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert image to RGB.\n",
    "    ans = pose.process(ii)\n",
    "    \n",
    "    if ans.pose_landmarks:  # If any landmarks are detected, then\n",
    "        landmarks = ans.pose_landmarks.landmark\n",
    "        data = np.array([(landmark.x, landmark.y, landmark.z) for landmark in landmarks]).flatten()\n",
    "        \n",
    "        return data, ans.pose_landmarks \n",
    "    return None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictEcercise(pose_landmarks):\n",
    "    if pose_landmarks is None:\n",
    "        return \"No landmarks detected\"\n",
    "    # reshape the landmards to sent to my NN \n",
    "    input = pose_landmarks.reshape(1, -1) \n",
    "    ans = model.predict(input)\n",
    "    finalans = label_encoder.inverse_transform([ans.argmax()])\n",
    "\n",
    "    return finalans[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def landmarkdrawing(image, pose_landmarks):\n",
    "    connections = [\n",
    "        (11, 13), (13, 15),  # Left arm\n",
    "        (12, 14), (14, 16),  # Right arm\n",
    "        (11, 12),            # Shoulders\n",
    "        (23, 25), (25, 27),  # Left leg\n",
    "        (24, 26), (26, 28),  # Right leg\n",
    "        (23, 24),            # Hips\n",
    "        (11, 23), (12, 24)   # Connect torso to hips\n",
    "    ]\n",
    "\n",
    "#for the lines.\n",
    "    for start_idx, end_idx in connections:\n",
    "        start = pose_landmarks.landmark[start_idx]\n",
    "        end = pose_landmarks.landmark[end_idx]\n",
    "        start_point = (int(start.x * image.shape[1]), int(start.y * image.shape[0]))\n",
    "        end_point = (int(end.x * image.shape[1]), int(end.y * image.shape[0]))\n",
    "        cv2.line(image, start_point, end_point, (0, 0, 255), 2)  # using red clr."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#myimg = 'images/jumpingjack.jpg'  \n",
    "#myimg = 'images/pullup4.jpg'\n",
    "myimg = 'images/st.jpeg'\n",
    "#myimg = 'images/jj.jpg'\n",
    "#myimg = 'images/def.png'\n",
    "image = cv2.imread(myimg)  # convert image to numpy array.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP  Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "\n",
      "0: 480x640 1 person, 130.0ms\n",
      "Speed: 5.4ms preprocess, 130.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "exercise: jumping_jacks_up\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: \n",
    "#         detect person\n",
    "#                      Bounding Box Detection Using YOLO v5\n",
    "\n",
    "ci, boximg = BoundingBoxDetection(image)\n",
    "\n",
    "# if person detected:\n",
    "if ci is not None: \n",
    "    # Step 2:\n",
    "    #        3D Pose Estimation Using a MediaPipe Model\n",
    "\n",
    "    p_lm, l_p = Pose3DEstimation(ci)\n",
    "    # if data received:\n",
    "    if p_lm is not None:\n",
    "        # Step 3: \n",
    "        #       Custom CNN for Exercise Classification\n",
    "        label = predictEcercise(p_lm)\n",
    "        print(f'exercise: {label}')\n",
    "\n",
    "        # Step 4:\n",
    "        #         Mapping and Visualization\n",
    "        landmarkdrawing(boximg, l_p)\n",
    "        cv2.putText(boximg, f'Exercise: {label}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.imshow('exercise', boximg)\n",
    "        \n",
    "        # save the output: \n",
    "        output_folder = 'outputs_yolov5'\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        output_image_path = os.path.join(output_folder, 'ansnewagain.jpg') \n",
    "        cv2.imwrite(output_image_path, boximg)\n",
    "        \n",
    "        \n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print('No pose landmarks detected.')\n",
    "else:\n",
    "    print('No person detected in the image.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
